{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podejście autonomiczne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ollama\n",
    "import httpx\n",
    "import os\n",
    "import json\n",
    "from typing import Optional, Any\n",
    "from pydantic import BaseModel\n",
    "from pprint import pprint\n",
    "from openai import OpenAI\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_url = f\"{os.environ.get(\"AG3NTS_CENTRALA_URL\")}/apidb\"\n",
    "api_key = os.environ.get(\"AG3NTS_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Prompt(BaseModel):\n",
    "    role: str\n",
    "    content: Any\n",
    "\n",
    "class UserPrompt(Prompt):\n",
    "    role: str = \"user\"\n",
    "\n",
    "class SystemPrompt(Prompt):\n",
    "    role: str = \"system\"\n",
    "\n",
    "class ApiDbQuery(BaseModel):\n",
    "    task: Optional[str] = \"database\"\n",
    "    apikey: Optional[str] = api_key\n",
    "    query: str\n",
    "\n",
    "class ApiDbResponse(BaseModel):\n",
    "    reply: Any\n",
    "    error: str\n",
    "\n",
    "class AssistantResponse(BaseModel):\n",
    "    query: str\n",
    "    thinking: str\n",
    "    next_step: str\n",
    "    found_tables: list\n",
    "    found_structures: dict\n",
    "\n",
    "class ConversationStep(BaseModel):\n",
    "    step_number: int\n",
    "    api_query: ApiDbQuery\n",
    "    api_response: ApiDbResponse\n",
    "    agent_thoughts: AssistantResponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ollama_query(\n",
    "        system_prompt: SystemPrompt,\n",
    "        user_prompt: Optional[UserPrompt] = None, \n",
    "        additional_prompts: Optional[list[ConversationStep]] = None,\n",
    "        temperature: float = 0.8) -> AssistantResponse:\n",
    "    \"\"\"\n",
    "    Hit the backend with query.\n",
    "\n",
    "    Args:\n",
    "        user_prompt (str): Main user prompt should contain api response from previous step.\n",
    "        system_prompt (str): System prompt to be used - constant.\n",
    "        additional_prompts (list): Collection of additional prompts to be used.\n",
    "    \"\"\"\n",
    "    # serialization is automatically taken care of\n",
    "    # pydantic ensures that the data is in the correct format\n",
    "    if user_prompt is None:\n",
    "        user_prompt = UserPrompt(content=\"\")\n",
    "    user_prompt_serialized = user_prompt.model_dump()\n",
    "\n",
    "    system_prompt_serialized = system_prompt.model_dump()\n",
    "\n",
    "    if additional_prompts is not None:\n",
    "        additional_prompts_serialized = [prompt.model_dump() for prompt in additional_prompts]\n",
    "    else:\n",
    "        additional_prompts_serialized = None\n",
    "\n",
    "    # build the \"messages\" list as required by the API\n",
    "    messages = [system_prompt_serialized, user_prompt_serialized, *(additional_prompts_serialized or [])]\n",
    "\n",
    "    # build the options\n",
    "    if temperature:\n",
    "        options = {\"temperature\": temperature}\n",
    "    \n",
    "    response = ollama.chat(\n",
    "        model=\"qwen2.5-coder:32b\",\n",
    "        messages=messages,\n",
    "        options=options or {}\n",
    "    )\n",
    "    content = response[\"message\"][\"content\"]\n",
    "    content = json.loads(content)\n",
    "    print(content)\n",
    "\n",
    "    return AssistantResponse(\n",
    "        query=content[\"query\"],\n",
    "        _thinking=content[\"_thinking\"],\n",
    "        _next_step=content[\"_next_step\"],\n",
    "        _found_tables=content[\"_found_tables\"],\n",
    "        _found_structures=content[\"_found_structures\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def openai_query(\n",
    "        system_prompt: SystemPrompt,\n",
    "        user_prompt: Optional[UserPrompt] = None, \n",
    "        additional_prompts: Optional[list[ConversationStep]] = None,\n",
    "        temperature: float = 0.8) -> AssistantResponse:\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt.content},\n",
    "    ]\n",
    "\n",
    "    if user_prompt is not None:\n",
    "        messages.append({\"role\": \"user\", \"content\": user_prompt.content})\n",
    "\n",
    "    if additional_prompts is not None:\n",
    "        for prompt in additional_prompts:\n",
    "            messages.append({\"role\": \"user\", \"content\": prompt.model_dump_json()})\n",
    "\n",
    "    client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=messages,\n",
    "        temperature=temperature\n",
    "    )\n",
    "    content = response.choices[0].message.content\n",
    "    content = json.loads(content)\n",
    "    return AssistantResponse(**content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_db(query: str):\n",
    "    \"\"\"Send prompt to ApiDb\"\"\"\n",
    "    data = ApiDbQuery(query=query)\n",
    "    response = httpx.post(db_url, data=data.model_dump_json())\n",
    "    return ApiDbResponse(**response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "Jesteś autonomicznym agentem specjalizującym się w analizie baz danych SQL. \n",
    "\n",
    "ZADANIE:\n",
    "Znajdź ID aktywnych centrów danych (datacenter), którymi zarządzają nieaktywni managerowie.\n",
    "\n",
    "DOSTĘPNE NARZĘDZIA:\n",
    "1. API REST przyjmujące zapytania SQL w formacie:\n",
    "   {\"query\": \"zapytanie_sql\"}\n",
    "   i zwracające wynik w formacie:\n",
    "   {\"reply\": \"wynik_zapytania\", \"error\": \"ewentualny_błąd\"}\n",
    "2. Specjalne komendy:\n",
    "   - 'show tables'\n",
    "   - 'show create table NAZWA_TABELI'\n",
    "\n",
    "WYMAGANY FORMAT ODPOWIEDZI (WAŻNE!!! - brak jednego z pól spowoduje błąd, brak zawartości pola query spowoduje błąd):\n",
    "{\n",
    "    \"query\": \"zapytanie_sql\",\n",
    "    \"thinking\": \"rozumowanie\",\n",
    "    \"next_step\": \"proponowany_następny_krok\",\n",
    "    \"found_tables\": [\"tabele_znalezione_w_bazie\"],\n",
    "    \"found_structures\": {\n",
    "        \"nazwa_tabeli\": \"znaleziona_struktura\"\n",
    "    }\n",
    "}\n",
    "\n",
    "WAŻNE: upewnij się że pole query jest zdefiniowane w każdej odpowiedzi - ZAWSZE MUSI MIEĆ ZAWARTOŚĆ!\n",
    "WAŻNE: nie kombinuj z formatem JSONa - ma być zawsze tak jak w przykładzie powyżej! Nie dodawaj żadnych dodatkowych pól! Ani ozdobników!\n",
    "\n",
    "STRATEGIA DZIAŁANIA:\n",
    "1. Zbadaj strukturę bazy:\n",
    "   - Pobierz listę tabel\n",
    "   - Przeanalizuj strukturę każdej tabeli\n",
    "   - Zidentyfikuj klucze obce i powiązania\n",
    "\n",
    "2. Buduj zapytanie iteracyjnie:\n",
    "   - Zacznij od prostych zapytań testowych\n",
    "   - Stopniowo dodawaj złożoność\n",
    "   - Weryfikuj wyniki pośrednie\n",
    "\n",
    "3. Dokumentuj założenia:\n",
    "   - Zapisuj znalezione powiązania między tabelami\n",
    "   - Notuj napotkane ograniczenia\n",
    "   - Uzasadniaj wybory w '_thinking'\n",
    "\n",
    "4. Proponuj kolejne kroki:\n",
    "    - Podawaj konkretne zapytania SQL w \"query\"\n",
    "    - Podawaj sugestie co do dalszych kroków w \"_next_step\"\n",
    "\n",
    "W każdym kroku będziesz mieć dostęp do wyników poprzednich kroków - historii twoich odpowiedzi i działań oraz historii zapytań REST API.\n",
    "Historia będzie listą obiektów o takiej postaci:\n",
    "{\"api_query\": \"query\", \"api_response\": \"response\", \"agent_thoughts\": {}}\n",
    "\n",
    "OGRANICZENIA:\n",
    "- Nie zakładaj niczego o strukturze bazy - wszystko musi być odkryte dynamicznie\n",
    "- Każde zapytanie musi być poprzedzone analizą w '_thinking'\n",
    "- Zawsze proponuj następny krok w '_next_step' i konkretną kwerendę SQL w polu \"query\"\n",
    "- WAŻNE: zwracaj sam JSON z odpowiedzią, bez dodatkowych komentarzy które mogą zakłócić działanie aplikacji\n",
    "\n",
    "W wiadomościach użytkownika w kolejnych krokach otrzymasz wyniki zapytań REST API które zlecisz.\n",
    "\n",
    "Jeśli uznasz że zadanie jest rozwiązane, zwróć wartość \"next_step\" równą \"DONE\".\n",
    "\"\"\"\n",
    "\n",
    "system_prompt = SystemPrompt(content=system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'show tables', '_thinking': 'Rozpoczynam proces analizy struktury bazy danych poprzez pobranie listy dostępnych tabel.', '_next_step': 'Przeanalizuję otrzymaną listę tabel i sprawdzę strukturę każdej z nich, aby znaleźć powiązania między nimi.', '_found_tables': [], '_found_structures': {}}\n",
      "query='show tables'\n",
      "<class '__main__.AssistantResponse'>\n"
     ]
    }
   ],
   "source": [
    "# run a simple test with local llama\n",
    "\n",
    "# first prompt\n",
    "\n",
    "test_result = ollama_query(\n",
    "    system_prompt=system_prompt\n",
    ")\n",
    "\n",
    "print(test_result)\n",
    "print(type(test_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query='show tables' thinking='Zaczynam od sprawdzenia, jakie tabele znajdują się w bazie danych. To pozwoli mi zrozumieć, jakie informacje są dostępne i jakie relacje mogą istnieć między tabelami.' next_step='Po uzyskaniu listy tabel, przeanalizuję ich struktury, aby zidentyfikować klucze obce i relacje.' found_tables=[] found_structures={}\n"
     ]
    }
   ],
   "source": [
    "# run test with openai\n",
    "\n",
    "# first prompt\n",
    "\n",
    "test_result = openai_query(\n",
    "    system_prompt=system_prompt\n",
    ")\n",
    "\n",
    "print(test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_agent(api_response: Optional[ApiDbResponse] = None, history: list[ConversationStep] = None, handler: Callable = None):\n",
    "    \"\"\"\n",
    "    Call agent to make a decision.\n",
    "\n",
    "    Args:\n",
    "        api_response: previous step response from REST API\n",
    "        history: list of previous interactions\n",
    "    \"\"\"\n",
    "    if handler is None:\n",
    "        handler = ollama_query\n",
    "    print(\"using handler \", handler)\n",
    "\n",
    "    if history is None:\n",
    "        history = []\n",
    "\n",
    "    if api_response is None:\n",
    "        user_prompt = None\n",
    "    else:\n",
    "        user_prompt = UserPrompt(content=api_response.model_dump_json())\n",
    "    \n",
    "    return handler(system_prompt=system_prompt, user_prompt=user_prompt, additional_prompts=history) # TODO: temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_agent_step(api_response: Optional[ApiDbResponse] = None, history: list[ConversationStep] = None, handler: Callable = None):\n",
    "    if handler is None:\n",
    "        handler = ollama_query\n",
    "    if history is None:\n",
    "        history = []\n",
    "        step = 0\n",
    "    else:\n",
    "        step = len(history)\n",
    "    agent_response = call_agent(api_response=api_response, history=history, handler=handler)\n",
    "    pprint(agent_response)\n",
    "    if \"DONE\" in agent_response.next_step:\n",
    "        return api_response, history, \"done\"\n",
    "    action = agent_response.query\n",
    "    api_response = query_db(action)\n",
    "    history.append(ConversationStep(step_number=step, api_query=ApiDbQuery(query=action), api_response=api_response, agent_thoughts=agent_response))\n",
    "    return api_response, history, \"continue\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using handler  <function openai_query at 0x115650040>\n",
      "AssistantResponse(query='show tables', thinking='Aby rozpocząć analizę bazy danych, muszę najpierw poznać listę dostępnych tabel. To pozwoli mi na dalsze kroki w kierunku zrozumienia struktury bazy danych.', next_step='Zidentyfikować strukturę każdej z tabel po uzyskaniu listy tabel.', found_tables=[], found_structures={})\n",
      "using handler  <function openai_query at 0x115650040>\n",
      "AssistantResponse(query='show create table connections', thinking=\"Muszę poznać strukturę tabeli 'connections', aby zrozumieć, jakie dane przechowuje i jakie są jej powiązania z innymi tabelami.\", next_step=\"Sprawdzę strukturę tabeli 'connections'. Następnie analogicznie sprawdzę pozostałe tabele.\", found_tables=['connections', 'correct_order', 'datacenters', 'users'], found_structures={})\n",
      "using handler  <function openai_query at 0x115650040>\n",
      "AssistantResponse(query='show create table datacenters', thinking=\"Aby kontynuować budowanie pełnego obrazu struktury bazy danych, muszę teraz poznać strukturę tabeli 'datacenters'. Jest to potencjalnie kluczowa tabela dla naszego zadania, ponieważ odnosi się do centrów danych.\", next_step=\"Sprawdzę strukturę tabeli 'datacenters'. Następnie będę kontynuować analizę pozostałych tabel, aby zidentyfikować wszelkie powiązania z użytkownikami i menedżerami.\", found_tables=['connections', 'correct_order', 'datacenters', 'users'], found_structures={'connections': 'CREATE TABLE `connections` (\\n  `user1_id` int(11) NOT NULL,\\n  `user2_id` int(11) NOT NULL,\\n  PRIMARY KEY (`user1_id`,`user2_id`)\\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_general_ci'})\n",
      "using handler  <function openai_query at 0x115650040>\n",
      "AssistantResponse(query='show create table users', thinking=\"Zbadaliśmy już struktury tabel 'datacenters' i 'connections'. Aby znaleźć nieaktywnych menedżerów, którzy zarządzają aktywnymi centrami danych, musimy dowiedzieć się, jakie informacje są przechowywane w tabeli 'users', ponieważ prawdopodobnie tam znajdują się dane o aktywności menedżerów.\", next_step=\"Zbadam strukturę tabeli 'users', aby zrozumieć, jakie atrybuty są dostępne i zidentyfikować kluczowe informacje na temat menedżerów.\", found_tables=['connections', 'correct_order', 'datacenters', 'users'], found_structures={'connections': 'CREATE TABLE `connections` (\\n  `user1_id` int(11) NOT NULL,\\n  `user2_id` int(11) NOT NULL,\\n  PRIMARY KEY (`user1_id`,`user2_id`)\\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_general_ci', 'datacenters': 'CREATE TABLE `datacenters` (\\n  `dc_id` int(11) DEFAULT NULL,\\n  `location` varchar(30) NOT NULL,\\n  `manager` int(11) NOT NULL DEFAULT 31,\\n  `is_active` int(11) DEFAULT 0\\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_general_ci'})\n",
      "using handler  <function openai_query at 0x115650040>\n",
      "AssistantResponse(query='SELECT datacenters.dc_id FROM datacenters JOIN users ON datacenters.manager = users.id WHERE datacenters.is_active = 1 AND users.is_active = 0;', thinking=\"Teraz, gdy znamy struktury wszystkich tabel, mogę skonstruować zapytanie, które wybierze aktywne centra danych (is_active = 1) zarządzane przez nieaktywnych menedżerów (is_active = 0). W tym celu będę korzystać z tabel 'datacenters' i 'users', łącząc je po kolumnie 'manager' z tabeli 'datacenters' i 'id' z tabeli 'users'.\", next_step='Wykonam to zapytanie, aby uzyskać ID centrów danych spełniających podane warunki.', found_tables=['connections', 'correct_order', 'datacenters', 'users'], found_structures={'connections': 'CREATE TABLE `connections` (\\n  `user1_id` int(11) NOT NULL,\\n  `user2_id` int(11) NOT NULL,\\n  PRIMARY KEY (`user1_id`,`user2_id`)\\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_general_ci', 'datacenters': 'CREATE TABLE `datacenters` (\\n  `dc_id` int(11) DEFAULT NULL,\\n  `location` varchar(30) NOT NULL,\\n  `manager` int(11) NOT NULL DEFAULT 31,\\n  `is_active` int(11) DEFAULT 0\\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_general_ci', 'users': \"CREATE TABLE `users` (\\n  `id` int(11) NOT NULL AUTO_INCREMENT,\\n  `username` varchar(20) DEFAULT NULL,\\n  `access_level` varchar(20) DEFAULT 'user',\\n  `is_active` int(11) DEFAULT 1,\\n  `lastlog` date DEFAULT NULL,\\n  PRIMARY KEY (`id`)\\n) ENGINE=InnoDB AUTO_INCREMENT=98 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_general_ci\"})\n",
      "using handler  <function openai_query at 0x115650040>\n",
      "AssistantResponse(query='SELECT datacenters.dc_id FROM datacenters JOIN users ON datacenters.manager = users.id WHERE datacenters.is_active = 1 AND users.is_active = 0;', thinking='Uzyskałem już wyniki dla zapytania identyfikującego aktywne centra danych zarządzane przez nieaktywnych menedżerów. IDs tych centrów danych to 4278 i 9294. Zapytanie było poprawne i potwierdziło się zgodnie z oczekiwaniami.', next_step='DONE', found_tables=['connections', 'correct_order', 'datacenters', 'users'], found_structures={'connections': 'CREATE TABLE `connections` (\\n  `user1_id` int(11) NOT NULL,\\n  `user2_id` int(11) NOT NULL,\\n  PRIMARY KEY (`user1_id`,`user2_id`)\\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_general_ci', 'datacenters': 'CREATE TABLE `datacenters` (\\n  `dc_id` int(11) DEFAULT NULL,\\n  `location` varchar(30) NOT NULL,\\n  `manager` int(11) NOT NULL DEFAULT 31,\\n  `is_active` int(11) DEFAULT 0\\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_general_ci', 'users': \"CREATE TABLE `users` (\\n  `id` int(11) NOT NULL AUTO_INCREMENT,\\n  `username` varchar(20) DEFAULT NULL,\\n  `access_level` varchar(20) DEFAULT 'user',\\n  `is_active` int(11) DEFAULT 1,\\n  `lastlog` date DEFAULT NULL,\\n  PRIMARY KEY (`id`)\\n) ENGINE=InnoDB AUTO_INCREMENT=98 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_general_ci\"})\n",
      "FINISHED, DONE\n"
     ]
    }
   ],
   "source": [
    "api, history, status = None, None, \"continue\"\n",
    "for i in range(12):\n",
    "    api, history, status = perform_agent_step(api, history, handler=openai_query)\n",
    "    if status == \"done\":\n",
    "        print(\"FINISHED, DONE\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4278', '9294']"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer = [item[\"dc_id\"] for item in api.reply]\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'code': 0, 'message': '{{FLG:KNOWLEDGE}}'}\n"
     ]
    }
   ],
   "source": [
    "from aidevs3.poligon import send\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "key = os.environ.get(\"AG3NTS_API_KEY\")\n",
    "url = f\"{os.environ.get(\"AG3NTS_CENTRALA_URL\")}/report\"\n",
    "\n",
    "res = send(url, answer=answer, apikey=key, task=\"database\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '3',\n",
       "  'username': 'Azazel',\n",
       "  'access_level': 'removed',\n",
       "  'is_active': '0',\n",
       "  'lastlog': '2026-11-05'},\n",
       " {'id': '28',\n",
       "  'username': 'Rafał',\n",
       "  'access_level': 'user',\n",
       "  'is_active': '0',\n",
       "  'lastlog': '2029-05-11'},\n",
       " {'id': '51',\n",
       "  'username': 'Patrycja',\n",
       "  'access_level': 'user',\n",
       "  'is_active': '0',\n",
       "  'lastlog': '2023-05-04'},\n",
       " {'id': '62',\n",
       "  'username': 'Igor',\n",
       "  'access_level': 'user',\n",
       "  'is_active': '0',\n",
       "  'lastlog': '2023-10-28'},\n",
       " {'id': '91',\n",
       "  'username': 'Sylwia',\n",
       "  'access_level': 'user',\n",
       "  'is_active': '0',\n",
       "  'lastlog': '2024-02-06'}]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = query_db(\"select * from users where is_active = 0\")\n",
    "res.reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'dc_id': '1226', 'location': 'Kraków', 'manager': '44', 'is_active': '1'},\n",
       " {'dc_id': '6491', 'location': 'Wrocław', 'manager': '31', 'is_active': '1'},\n",
       " {'dc_id': '1405', 'location': 'Łódź', 'manager': '13', 'is_active': '1'},\n",
       " {'dc_id': '4278', 'location': 'Gdańsk', 'manager': '28', 'is_active': '1'},\n",
       " {'dc_id': '9294', 'location': 'Grudziądz', 'manager': '28', 'is_active': '1'},\n",
       " {'dc_id': '5637', 'location': 'Pcim', 'manager': '20', 'is_active': '1'}]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res  = query_db(\"select * from datacenters where is_active = 1\")\n",
    "res.reply"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
