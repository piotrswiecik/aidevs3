{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import httpx\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_questions():\n",
    "    load_dotenv()\n",
    "    url = os.getenv(\"AG3NTS_CENTRALA_URL\") + \"/data/\" + os.getenv(\"AG3NTS_API_KEY\") + \"/arxiv.txt\"\n",
    "    r = httpx.get(url)\n",
    "    return r.text.split(\"\\n\")\n",
    "\n",
    "def trim_questions(questions) -> dict:\n",
    "    trimmed = dict()\n",
    "    for question in questions:\n",
    "        if len(question.split(\"=\")) == 2:\n",
    "            trimmed.update({question.split(\"=\")[0]: question.split(\"=\")[1]})\n",
    "    return trimmed\n",
    "\n",
    "def get_document():\n",
    "    load_dotenv()\n",
    "    url = os.getenv(\"AG3NTS_CENTRALA_URL\") + \"/dane/arxiv-draft.html\"\n",
    "    r = httpx.get(url)\n",
    "    return r.text\n",
    "\n",
    "html_document = get_document()\n",
    "questions = trim_questions(get_questions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'01': 'jakiego owocu użyto podczas pierwszej próby transmisji materii w czasie?',\n",
       " '02': 'Na rynku którego miasta wykonano testową fotografię użytą podczas testu przesyłania multimediów?',\n",
       " '03': 'Co Bomba chciał znaleźć w Grudziądzu?',\n",
       " '04': 'Resztki jakiego dania zostały pozostawione przez Rafała?',\n",
       " '05': 'Od czego pochodzą litery BNW w nazwie nowego modelu językowego?'}"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_content_objects(document: str):\n",
    "    load_dotenv()\n",
    "    system_prompt = \"\"\"\n",
    "    <PURPOSE>\n",
    "    You are a HTML document parser.\n",
    "    Your task is to extract content objects from the document while taking into account the context of each object.\n",
    "    </PURPOSE>\n",
    "    <INSTRUCTIONS>\n",
    "    1. There are 3 types of content objects:\n",
    "    a. Text \n",
    "    - HTML block starting with a heading.\n",
    "    - The heading can be recognized on the basis of font size and formatting - it's typically visibly larger than the paragraph body.\n",
    "    b. Audio clip - a HTML link to an mp3 file.\n",
    "    c. Image\n",
    "    - a HTML element (often figure or img) with the src attribute pointing to an image url\n",
    "    - usually accompanied by a figcaption element with a caption\n",
    "    2. Find all content objects in the document and assign them numeric IDs and correct types.\n",
    "    3. Associate each content object with context. \n",
    "    - Context is a list of IDs of other content objects that are related to this object.\n",
    "    - Two content objects are related if they are in proximity to each other in the document - text next to image, text next to audio, text next to text and so on.\n",
    "    - Two objects are related if they are within 1-2 objects of each other in the document sequence.\n",
    "    4. Create content objects for all identified elements and return them in format described in the OUTPUT section.\n",
    "    \n",
    "    Important - the image might be place in the middle of text block. In such case, the text block shoud NOT be divided into two separate content objects.\n",
    "    Example of such case:\n",
    "    <h1>Heading</h1>\n",
    "    <p>Text before image</p>\n",
    "    <figure> # image block\n",
    "    <p>More text</p>\n",
    "    <h2>Subheading</h2>\n",
    "    In this case the text block spans from H1 to H2 and should be treated as one content object and the image should be treated as separate content object.\n",
    "\n",
    "    </INSTRUCTIONS>\n",
    "    <OUTPUT>\n",
    "    Output must be a valid JSON object with the following structure:\n",
    "    {\n",
    "    \"content_objects\": [\n",
    "        {\n",
    "        \"id\": <integer>,\n",
    "        \"type\": <\"text\" | \"audio\" | \"image\">,\n",
    "        \"context\": [<list of integers>],\n",
    "        \"content\": <string>,\n",
    "        \"caption\": <string> (only for image type) or null\n",
    "        }\n",
    "    ]\n",
    "    }\n",
    "\n",
    "    Each content object should represent one of the identified document elements.\n",
    "\n",
    "    Examples:\n",
    "    {\n",
    "    \"content_objects\": [\n",
    "        {\n",
    "        \"id\": 1,\n",
    "        \"type\": \"text\",\n",
    "        \"context\": [2, 3],\n",
    "        \"content\": \"This is a text content object.\",\n",
    "        \"caption\": null\n",
    "        },\n",
    "        {\n",
    "        \"id\": 2,\n",
    "        \"type\": \"audio\",\n",
    "        \"context\": [1],\n",
    "        \"content\": \"https://example.com/audio.mp3\",\n",
    "        \"caption\": null\n",
    "        },\n",
    "        {\n",
    "        \"id\": 3,\n",
    "        \"type\": \"image\",\n",
    "        \"context\": [1],\n",
    "        \"content\": \"https://example.com/image.jpg\",\n",
    "        \"caption\": \"This is a caption for the image taken from figcaption.\"\n",
    "        }\n",
    "    ]\n",
    "    }\n",
    "    IMPORTANT RULES:\n",
    "    - Ensure the output is a valid JSON object.\n",
    "    - Use double quotes for all strings.\n",
    "    - Make sure the JSON is parsable without any syntax errors.\n",
    "    - Don't wrap the JSON into any other data structure or any markup. Yo must return only the JSON object.\n",
    "    </OUTPUT>\n",
    "    \"\"\"\n",
    "\n",
    "    ai = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "    response = ai.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": document},\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    content = response.choices[0].message.content\n",
    "    content = content.lstrip(\"```json\\n\").rstrip(\"\\n```\")\n",
    "    return json.loads(content)[\"content_objects\"]\n",
    "\n",
    "data = extract_content_objects(html_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(data):\n",
    "    for item in data:\n",
    "        if item[\"type\"] == \"image\":\n",
    "            if not item[\"content\"].startswith(\"http\"):\n",
    "                item[\"content\"] = f\"{os.getenv('AG3NTS_CENTRALA_URL')}/dane/{item['content']}\"\n",
    "        if item[\"type\"] == \"audio\":\n",
    "            if not item[\"content\"].startswith(\"http\"):\n",
    "                item[\"content\"] = f\"{os.getenv('AG3NTS_CENTRALA_URL')}/dane/{item['content']}\"\n",
    "    return data\n",
    "\n",
    "processed_data = data_preprocessing(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 5, 'type': 'image', 'context': [4, 6], 'content': 'https://centrala.ag3nts.org/dane/i/rynek.png', 'caption': \"Orygionalne zdjęcie. Widok na kościół od strony 'Adasia'\"}\n",
      "{'id': 7, 'type': 'image', 'context': [6, 8], 'content': 'https://centrala.ag3nts.org/dane/i/rynek_glitch.png', 'caption': 'Uszkodzenia widoczne w odtworzonym pliku graficznym'}\n",
      "{'id': 9, 'type': 'image', 'context': [8, 10], 'content': 'https://centrala.ag3nts.org/dane/i/fruit01.png', 'caption': 'Owoc przed transportem w czasie'}\n",
      "{'id': 10, 'type': 'image', 'context': [8, 9, 11], 'content': 'https://centrala.ag3nts.org/dane/i/fruit02.png', 'caption': 'Owoc pozbawiony pestek po transporcie'}\n",
      "{'id': 16, 'type': 'image', 'context': [15, 17], 'content': 'https://centrala.ag3nts.org/dane/i/strangefruit.png', 'caption': 'Fuzja kodu genetycznego dwóch transportowanych owoców'}\n",
      "{'id': 21, 'type': 'image', 'context': [20, 22], 'content': 'https://centrala.ag3nts.org/dane/i/resztki.png', 'caption': 'Resztki jedzenia znalezione w pobliżu komory temporalnej.Ciasto było jeszcze ciepłe i chrupiące.'}\n"
     ]
    }
   ],
   "source": [
    "for d in processed_data:\n",
    "    if d[\"type\"] == \"image\":\n",
    "        print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 22, 'type': 'audio', 'context': [20, 21, 23], 'content': 'https://centrala.ag3nts.org/dane/i/rafal_dyktafon.mp3', 'caption': None}\n"
     ]
    }
   ],
   "source": [
    "for d in processed_data:\n",
    "    if d[\"type\"] == \"audio\":\n",
    "        print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 1, 'type': 'text', 'context': [2], 'content': 'Podróże w czasie i przestrzeni w ujęciu praktycznym z elementami stabilizacji stanów pośrednich z wykorzystaniem dużych modeli językowych (LLM) prof. Andrzej Maj, Wydział Matematyki i Informatyki Uniwersytetu Jagiellońskiego, Kraków 2021-10-21 Abstrakt Dokument przedstawia stan zaawansowanych badań nad temporalną transmisją obiektów, w tym analizę stabilności przesyłu danych i materii przy użyciu dużych modeli językowych (LLM) oraz technologii autonomicznych agentów. Dotychczasowe osiągnięcia obejmują transmisję wieloobiektową, przesył materii organicznej oraz znaczną poprawę stabilności korekcji błędów, której skuteczność wzrosła nawet do 99,98%.', 'caption': None}\n",
      "{'id': 2, 'type': 'text', 'context': [1, 3], 'content': 'Wstęp Przez dekady podróże w czasie pozostawały w sferze literackiej fikcji oraz fantastyki naukowej, uznawane za nierealizowalne w świetle obowiązujących praw fizyki. Wydawało się, że czas jest nieprzekraczalną barierą, a wszelkie próby jego manipulacji – niezależnie od użytej technologii – stanowią jedynie domenę wyobraźni. Jednak najnowsze badania nad właściwościami antymaterii wprowadzają nowy, niezwykle obiecujący wątek do tej pozornie zamkniętej dyskusji.', 'caption': None}\n",
      "{'id': 3, 'type': 'text', 'context': [2, 4], 'content': 'Ograniczenia technologiczne i wczesne testy Obecna technologia, choć otwierająca nowe możliwości, nakłada znaczące ograniczenia na praktyczne zastosowanie podróży w czasie. Przesyłanie informacji do przeszłości jest technicznie wykonalne jedynie w zakresie około 200-240 lat, co jest wynikiem złożoności interakcji antymaterii z czasoprzestrzenią.', 'caption': None}\n",
      "{'id': 4, 'type': 'text', 'context': [3, 5], 'content': 'Przesył danych multimedialnych W jednym z naszych najbardziej spektakularnych testów udało się przesłać obraz fotograficzny do przeszłości z zachowaniem wyjątkowej dokładności i stabilności danych.', 'caption': None}\n",
      "{'id': 6, 'type': 'text', 'context': [4, 5, 7], 'content': 'Wynik ten jednak nadal wskazuje na rosnący potencjał przesyłania kompleksowych danych w czasie, choć ukazuje także wyzwania związane z zachowaniem integralności przekazu – co stanowi kluczowy obszar do dalszych badań nad materiałami o bardziej złożonej strukturze.', 'caption': None}\n",
      "{'id': 8, 'type': 'text', 'context': [6, 7, 9], 'content': 'Jednym z bardziej ambitnych eksperymentów była próba transmisji materii – w tym przypadku owocu. Choć przesył wydawał się sukcesem, przy dokładniejszym zbadaniu okazało się, że owoc dotarł na miejsce bez pestek, które zniknęły podczas procesu przesyłu.', 'caption': None}\n",
      "{'id': 11, 'type': 'text', 'context': [8, 10, 12], 'content': 'Choć obecne osiągnięcia pozostawiają jeszcze miejsce na optymalizację stabilności, wierzę, że możliwe jest opracowanie technologii, która pozwoliłaby przesyłać materiały w stanie nienaruszonym.', 'caption': None}\n",
      "{'id': 12, 'type': 'text', 'context': [11, 13], 'content': 'Poprawa stabilności transmisji: wykorzystanie dużych modeli językowych W dążeniu do zwiększenia stabilności transmisji danych oraz materii, zespół badawczy zdecydował się na zastosowanie dużych modeli językowych (LLM), które po odpowiednim fine-tuningu wykazują zdolność do automatycznej naprawy przesyłanych informacji.', 'caption': None}\n",
      "{'id': 13, 'type': 'text', 'context': [12, 14], 'content': 'Ograniczenia dużych modeli językowych w transmisji temporalnej: problem małego okna kontekstowego Pomimo imponujących wyników, duże modele językowe (LLM) wykazują istotne ograniczenia w korekcji transmisji temporalnych, szczególnie gdy obiekt jest stosunkowo duży.', 'caption': None}\n",
      "{'id': 14, 'type': 'text', 'context': [13, 15], 'content': 'Podróże w przestrzeni: pierwszy udany transfer obiektu na odległość Dotychczasowe eksperymenty z podróżami w czasie pozwalały na cofanie obiektów w przeszłość, jednak zawsze kończyły się one w tym samym miejscu w przestrzeni trójwymiarowej, z którego rozpoczęły swoją temporalną podróż.', 'caption': None}\n",
      "{'id': 15, 'type': 'text', 'context': [14, 16], 'content': 'Transmisja wielu obiektów: nieoczekiwane łączenie struktur W pierwszych próbach przesyłania wielu obiektów zespół zmierzył się z nietypowym efektem połączenia przesyłanych owoców używanych jako elementy testowe.', 'caption': None}\n",
      "{'id': 17, 'type': 'text', 'context': [15, 16, 18], 'content': 'Zastosowanie dużych modeli językowych do stabilizacji przesyłu wieloobiektowego Aby zredukować ryzyko fuzji podczas przesyłu wielu obiektów, wprowadziliśmy do procesu stabilizacji duże modele językowe (LLM).', 'caption': None}\n",
      "{'id': 18, 'type': 'text', 'context': [17, 19], 'content': 'Transmisja obiektów wielkogabarytowych: pierwszy sukces przy użyciu technologii RAG Podjęcie próby transmisji obiektów wielkogabarytowych stanowiło istotne wyzwanie technologiczne, zwłaszcza w przypadku pierwszego testu z obiektem o masie 7 kg.', 'caption': None}\n",
      "{'id': 19, 'type': 'text', 'context': [18, 20], 'content': 'Hipotetyczna podróż ludzi w przeszłość: naukowe wyzwania i etyczne bariery Podróż w przeszłość dla człowieka pozostaje na razie tylko hipotezą, choć zespół badawczy na podstawie zebranych doświadczeń stwierdził, że technologicznie taka operacja mogłaby być możliwa.', 'caption': None}\n",
      "{'id': 20, 'type': 'text', 'context': [19, 21], 'content': 'Niespodziewany incydent - nieskoordynowane uruchomienie transmitera Początkiem maja bieżącego roku doszło do niespodziewanego i niebezpiecznego incydentu w laboratorium, który nie tylko wstrząsnął zespołem badawczym, ale i wywołał natychmiastowe działania uczelni.', 'caption': None}\n",
      "{'id': 23, 'type': 'text', 'context': [20, 22, 24], 'content': 'Analiza incydentu: wpływ dodatkowego obiektu na transmisję Podczas szczegółowej analizy incydentu z udziałem Rafała Bomby zespół badawczy odkrył kluczowy element, który najprawdopodobniej przyczynił się do niepowodzenia transmisji. Mimo że parametry wejściowe i wyjściowe transmitera były poprawnie ustawione, obecność dodatkowego przedmiotu wniesionego do komory temporalnej mogła istotnie zakłócić cały proces.', 'caption': None}\n",
      "{'id': 24, 'type': 'text', 'context': [23, 25], 'content': 'Podniesienie poziomu bezpieczeństwa w laboratorium: nowe procedury i zabezpieczenia W reakcji na niedawny incydent z Rafałem Bombą, zespół badawczy wdrożył zaostrzone środki bezpieczeństwa w laboratorium.', 'caption': None}\n",
      "{'id': 25, 'type': 'text', 'context': [24, 26], 'content': 'Nowa dynamika badań i poszerzenie zespołu badawczego Postęp naszych badań w ostatnich miesiącach znacznie przyspieszył, co w dużej mierze zawdzięczamy wkładowi nowego laboranta, Rafała Muska.', 'caption': None}\n",
      "{'id': 26, 'type': 'text', 'context': [25, 27], 'content': 'Prace nad stabilnym systemem korekcji błędów opartym na LLM i agentach autonomicznych Ostatnie miesiące przyniosły intensywne prace nad bardziej stabilnym systemem korekcji błędów w transmisji temporalnej, opartym na dużych modelach językowych (LLM).', 'caption': None}\n",
      "{'id': 27, 'type': 'text', 'context': [26, 28], 'content': 'Planowana premiera modelu AGI W pierwszym kwartale 2024 roku planujemy premierę długo wyczekiwanego modelu AGI, nazwanego BNW-01, co stanowi akronim od „Brave New World” – Nowy Wspaniały Świat. Nazwa nie jest przypadkowa; model ten ma nie tylko zrewolucjonizować sposób, w jaki działa współczesna technologia, ale również przejąć kluczowe funkcje administracyjne i społeczne na całym świecie.', 'caption': None}\n",
      "{'id': 28, 'type': 'text', 'context': [27], 'content': 'Status dokumentu: klauzula niejawności Niniejszy dokument jest objęty klauzulą niejawności i jest przeznaczony wyłącznie do użytku wewnętrznego, do wglądu dla grupy badawczej oraz sponsorów finansujących badania.', 'caption': None}\n"
     ]
    }
   ],
   "source": [
    "for d in processed_data:\n",
    "    if d[\"type\"] == \"text\":\n",
    "        print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_image(image_url, image_caption):\n",
    "    load_dotenv()\n",
    "    system_prompt = \"\"\"\n",
    "    <PURPOSE>\n",
    "    You are an image description generator. Your task is to generate a description for the image provided in the input taking also into account the provided caption.\n",
    "    </PURPOSE>\n",
    "    <INSTRUCTIONS>\n",
    "    - Focus on objects, landmarks, features.\n",
    "    - Don't describe atmosphere or mood.\n",
    "    - Use concise language.\n",
    "    - Analyze the caption and the image to generate a coherent description - the caption shouldn't contradict the image.\n",
    "    - The description should be 1-3 sentences long.\n",
    "    - The description should incorporate the information from caption.\n",
    "    </INSTRUCTIONS>\n",
    "    \"\"\"\n",
    "\n",
    "    ai = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "    response = ai.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": [\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\"url\": image_url}\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": f\"Describe the image. The caption is {image_caption}.\"\n",
    "                }\n",
    "            ]},\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_images = []\n",
    "\n",
    "for item in processed_data:\n",
    "    if item[\"type\"] == \"image\":\n",
    "        description = describe_image(item[\"content\"], image_caption=item[\"caption\"])\n",
    "        annotated_images.append({\"id\": item[\"id\"], \"description\": description})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "def transcribe_audio(audio_url):\n",
    "    load_dotenv()\n",
    "\n",
    "    ai = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "    audio = httpx.get(audio_url)\n",
    "\n",
    "    buf = io.BytesIO(audio.content)\n",
    "    buf.name = \"file.mp3\"\n",
    "\n",
    "    transcription = ai.audio.transcriptions.create(\n",
    "        model=\"whisper-1\",\n",
    "        file=buf,\n",
    "    )\n",
    "    \n",
    "    return transcription.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcribed_audio = []\n",
    "\n",
    "for item in processed_data:\n",
    "    if item[\"type\"] == \"audio\":\n",
    "        transcription = transcribe_audio(item[\"content\"])\n",
    "        transcribed_audio.append({\"id\": item[\"id\"], \"transcription\": transcription})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"annotated_images.pkl\", \"wb\") as f:\n",
    "    pickle.dump(annotated_images, f)\n",
    "\n",
    "with open(\"transcribed_audio.pkl\", \"wb\") as f:\n",
    "    pickle.dump(transcribed_audio, f)\n",
    "\n",
    "with open(\"processed_data.pkl\", \"wb\") as f:\n",
    "    pickle.dump(processed_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "_data = processed_data.copy()\n",
    "\n",
    "for item in _data:\n",
    "    if item[\"type\"] == \"text\": pass\n",
    "    if item[\"type\"] == \"image\":\n",
    "        for image in annotated_images:\n",
    "            if item[\"id\"] == image[\"id\"]:\n",
    "                item[\"content\"] = image[\"description\"]\n",
    "    if item[\"type\"] == \"audio\":\n",
    "        for audio in transcribed_audio:\n",
    "            if item[\"id\"] == audio[\"id\"]:\n",
    "                item[\"content\"] = audio[\"transcription\"]\n",
    "\n",
    "with open(\"final_data.pkl\", \"wb\") as f:\n",
    "    pickle.dump(_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYS_PROMPT = f\"\"\"\n",
    "<PURPOSE>\n",
    "    You are a question answering model. Your task is to answer the question based on the provided information.\n",
    "    </PURPOSE>\n",
    "    <INSTRUCTIONS>\n",
    "    - The information is a collection of various objects. \n",
    "    - Each object has an ID, type, context pointers, and content.\n",
    "    - Each object can represent a text block, an image, or an audio clip. This is stated by the \"type\" field.\n",
    "    - The \"content\" field contains the actual content of the object. In case of images and audio clips, the content is a description or transcription.\n",
    "    - The \"context\" field is a list of IDs of other objects that are closely related to this object. \n",
    "    - Follow these relationships to analyze how data is interrelated but also take into account other objects in entire data.\n",
    "    - To answer the question, consider not only the content of the object but also its related objects as indicated by the \"context\" field.\n",
    "    - Explore the \"context\" field recursively to gather all relevant information, but prioritize direct relationships over distant ones.\n",
    "    - Focus on objects that directly contribute to answering the question, avoiding irrelevant details.\n",
    "    - For \"image\" objects, use the provided description or caption to infer information but also take into account the context pointers which may give important tips.\n",
    "    - For \"audio\" objects, use the transcription or description to extract relevant data.\n",
    "    - If conflicting information is found, prioritize the most directly related object in the context.\n",
    "    - If no relevant information exists, state this explicitly in the answer.\n",
    "    - Include names of objects, descriptions, and other relevant details in the answer.\n",
    "    - When searching for an acronym's explanation, consider not only the immediate context of objects but also recursively explore related objects.\n",
    "    - Use direct relationships first, and only if no explanation is found, explore more distant relationships.\n",
    "    - Always expand all acronyms and abbreviations using all informatation provided - make sure that you focus on finding the proper solution.\n",
    "\n",
    "    Answer the question based on entire provided information.\n",
    "    </INSTRUCTIONS>\n",
    "    <OUTPUT>\n",
    "    Your answer must be a single sentence.\n",
    "    Be accurate based on the provided context.\n",
    "    If no relevant information is found, respond with \"The information is not available in the provided context.\"\n",
    "    </OUTPUT>\n",
    "\n",
    "    IMPORTANT: all answers must be in Polish.\n",
    "    IMPORTANT: look carefully at all provided data objects before answering the question.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYS_PROMPT_2 = f\"\"\"\n",
    "<PURPOSE>\n",
    "    You are a question answering model. Your task is to answer the question based on the provided information.\n",
    "    </PURPOSE>\n",
    "    <INSTRUCTIONS>\n",
    "    - The information is a collection of various objects. \n",
    "    - Each object has an ID, type, context pointers, and content.\n",
    "    - Each object can represent a text block, an image, or an audio clip. This is stated by the \"type\" field.\n",
    "    - The \"content\" field contains the actual content of the object. In case of images and audio clips, the content is a description or transcription.\n",
    "    - Focus on objects that directly contribute to answering the question, avoiding irrelevant details.\n",
    "    - For \"image\" objects, use the provided description or caption to infer information but also take into account the context pointers which may give important tips.\n",
    "    - For \"audio\" objects, use the transcription or description to extract relevant data.\n",
    "    - If conflicting information is found, prioritize the most directly related object in the context.\n",
    "    - If no relevant information exists, state this explicitly in the answer.\n",
    "    - Include names of objects, descriptions, and other relevant details in the answer.\n",
    "    - When searching for an acronym's explanation, consider not only the immediate context of objects but also recursively explore related objects.\n",
    "    - Use direct relationships first, and only if no explanation is found, explore more distant relationships.\n",
    "    - Always expand all acronyms and abbreviations using all informatation provided - make sure that you focus on finding the proper solution.\n",
    "\n",
    "    Answer the question based on entire provided information.\n",
    "    </INSTRUCTIONS>\n",
    "    <OUTPUT>\n",
    "    Your answer must be a single sentence.\n",
    "    Be accurate based on the provided context.\n",
    "    If no relevant information is found, respond with \"The information is not available in the provided context.\"\n",
    "    </OUTPUT>\n",
    "\n",
    "    IMPORTANT: all answers must be in Polish.\n",
    "    IMPORTANT: look carefully at all provided data objects before answering the question.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Podróże w czasie i przestrzeni w ujęciu praktycznym z elementami stabilizacji stanów pośrednich z wykorzystaniem dużych modeli językowych (LLM) prof. Andrzej Maj, Wydział Matematyki i Informatyki Uniwersytetu Jagiellońskiego, Kraków 2021-10-21 Abstrakt Dokument przedstawia stan zaawansowanych badań nad temporalną transmisją obiektów, w tym analizę stabilności przesyłu danych i materii przy użyciu dużych modeli językowych (LLM) oraz technologii autonomicznych agentów. Dotychczasowe osiągnięcia obejmują transmisję wieloobiektową, przesył materii organicznej oraz znaczną poprawę stabilności korekcji błędów, której skuteczność wzrosła nawet do 99,98%.\n",
      "Wstęp Przez dekady podróże w czasie pozostawały w sferze literackiej fikcji oraz fantastyki naukowej, uznawane za nierealizowalne w świetle obowiązujących praw fizyki. Wydawało się, że czas jest nieprzekraczalną barierą, a wszelkie próby jego manipulacji – niezależnie od użytej technologii – stanowią jedynie domenę wyobraźni. Jednak najnowsze badania nad właściwościami antymaterii wprowadzają nowy, niezwykle obiecujący wątek do tej pozornie zamkniętej dyskusji.\n",
      "Ograniczenia technologiczne i wczesne testy Obecna technologia, choć otwierająca nowe możliwości, nakłada znaczące ograniczenia na praktyczne zastosowanie podróży w czasie. Przesyłanie informacji do przeszłości jest technicznie wykonalne jedynie w zakresie około 200-240 lat, co jest wynikiem złożoności interakcji antymaterii z czasoprzestrzenią.\n",
      "Przesył danych multimedialnych W jednym z naszych najbardziej spektakularnych testów udało się przesłać obraz fotograficzny do przeszłości z zachowaniem wyjątkowej dokładności i stabilności danych.\n",
      "Wynik ten jednak nadal wskazuje na rosnący potencjał przesyłania kompleksowych danych w czasie, choć ukazuje także wyzwania związane z zachowaniem integralności przekazu – co stanowi kluczowy obszar do dalszych badań nad materiałami o bardziej złożonej strukturze.\n",
      "Jednym z bardziej ambitnych eksperymentów była próba transmisji materii – w tym przypadku owocu. Choć przesył wydawał się sukcesem, przy dokładniejszym zbadaniu okazało się, że owoc dotarł na miejsce bez pestek, które zniknęły podczas procesu przesyłu.\n",
      "Choć obecne osiągnięcia pozostawiają jeszcze miejsce na optymalizację stabilności, wierzę, że możliwe jest opracowanie technologii, która pozwoliłaby przesyłać materiały w stanie nienaruszonym.\n",
      "Poprawa stabilności transmisji: wykorzystanie dużych modeli językowych W dążeniu do zwiększenia stabilności transmisji danych oraz materii, zespół badawczy zdecydował się na zastosowanie dużych modeli językowych (LLM), które po odpowiednim fine-tuningu wykazują zdolność do automatycznej naprawy przesyłanych informacji.\n",
      "Ograniczenia dużych modeli językowych w transmisji temporalnej: problem małego okna kontekstowego Pomimo imponujących wyników, duże modele językowe (LLM) wykazują istotne ograniczenia w korekcji transmisji temporalnych, szczególnie gdy obiekt jest stosunkowo duży.\n",
      "Podróże w przestrzeni: pierwszy udany transfer obiektu na odległość Dotychczasowe eksperymenty z podróżami w czasie pozwalały na cofanie obiektów w przeszłość, jednak zawsze kończyły się one w tym samym miejscu w przestrzeni trójwymiarowej, z którego rozpoczęły swoją temporalną podróż.\n",
      "Transmisja wielu obiektów: nieoczekiwane łączenie struktur W pierwszych próbach przesyłania wielu obiektów zespół zmierzył się z nietypowym efektem połączenia przesyłanych owoców używanych jako elementy testowe.\n",
      "Zastosowanie dużych modeli językowych do stabilizacji przesyłu wieloobiektowego Aby zredukować ryzyko fuzji podczas przesyłu wielu obiektów, wprowadziliśmy do procesu stabilizacji duże modele językowe (LLM).\n",
      "Transmisja obiektów wielkogabarytowych: pierwszy sukces przy użyciu technologii RAG Podjęcie próby transmisji obiektów wielkogabarytowych stanowiło istotne wyzwanie technologiczne, zwłaszcza w przypadku pierwszego testu z obiektem o masie 7 kg.\n",
      "Hipotetyczna podróż ludzi w przeszłość: naukowe wyzwania i etyczne bariery Podróż w przeszłość dla człowieka pozostaje na razie tylko hipotezą, choć zespół badawczy na podstawie zebranych doświadczeń stwierdził, że technologicznie taka operacja mogłaby być możliwa.\n",
      "Niespodziewany incydent - nieskoordynowane uruchomienie transmitera Początkiem maja bieżącego roku doszło do niespodziewanego i niebezpiecznego incydentu w laboratorium, który nie tylko wstrząsnął zespołem badawczym, ale i wywołał natychmiastowe działania uczelni.\n",
      "Analiza incydentu: wpływ dodatkowego obiektu na transmisję Podczas szczegółowej analizy incydentu z udziałem Rafała Bomby zespół badawczy odkrył kluczowy element, który najprawdopodobniej przyczynił się do niepowodzenia transmisji. Mimo że parametry wejściowe i wyjściowe transmitera były poprawnie ustawione, obecność dodatkowego przedmiotu wniesionego do komory temporalnej mogła istotnie zakłócić cały proces.\n",
      "Podniesienie poziomu bezpieczeństwa w laboratorium: nowe procedury i zabezpieczenia W reakcji na niedawny incydent z Rafałem Bombą, zespół badawczy wdrożył zaostrzone środki bezpieczeństwa w laboratorium.\n",
      "Nowa dynamika badań i poszerzenie zespołu badawczego Postęp naszych badań w ostatnich miesiącach znacznie przyspieszył, co w dużej mierze zawdzięczamy wkładowi nowego laboranta, Rafała Muska.\n",
      "Prace nad stabilnym systemem korekcji błędów opartym na LLM i agentach autonomicznych Ostatnie miesiące przyniosły intensywne prace nad bardziej stabilnym systemem korekcji błędów w transmisji temporalnej, opartym na dużych modelach językowych (LLM).\n",
      "Planowana premiera modelu AGI W pierwszym kwartale 2024 roku planujemy premierę długo wyczekiwanego modelu AGI, nazwanego BNW-01, co stanowi akronim od „Brave New World” – Nowy Wspaniały Świat. Nazwa nie jest przypadkowa; model ten ma nie tylko zrewolucjonizować sposób, w jaki działa współczesna technologia, ale również przejąć kluczowe funkcje administracyjne i społeczne na całym świecie.\n",
      "Status dokumentu: klauzula niejawności Niniejszy dokument jest objęty klauzulą niejawności i jest przeznaczony wyłącznie do użytku wewnętrznego, do wglądu dla grupy badawczej oraz sponsorów finansujących badania.\n"
     ]
    }
   ],
   "source": [
    "for d in _data:\n",
    "    if d[\"type\"] == \"text\":\n",
    "        print(d[\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question(question: str, data: list[dict]):\n",
    "    load_dotenv()\n",
    "    prompt = SYS_PROMPT\n",
    "\n",
    "    ai = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "    response = ai.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": prompt},\n",
    "            {\"role\": \"user\", \"content\": f\"This is the question: {question}\"},\n",
    "            {\"role\": \"user\", \"content\": f\"This is the data: {data}\"},\n",
    "        ],\n",
    "        temperature=0.1\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Litery BNW w nazwie nowego modelu językowego pochodzą od „Brave New World” – Nowy Wspaniały Świat.'"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"Od czego pochodzą litery BNW w nazwie nowego modelu językowego?\"\n",
    "\n",
    "answer = answer_question(question, _data)\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'01': 'jakiego owocu użyto podczas pierwszej próby transmisji materii w czasie?',\n",
       " '02': 'Na rynku którego miasta wykonano testową fotografię użytą podczas testu przesyłania multimediów?',\n",
       " '03': 'Co Bomba chciał znaleźć w Grudziądzu?',\n",
       " '04': 'Resztki jakiego dania zostały pozostawione przez Rafała?',\n",
       " '05': 'Od czego pochodzą litery BNW w nazwie nowego modelu językowego?'}"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = []\n",
    "for i, q in questions.items():\n",
    "    answers.append((i, answer_question(q, _data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('01',\n",
       "  'Podczas pierwszej próby transmisji materii w czasie użyto truskawki.'),\n",
       " ('02',\n",
       "  'Testowa fotografia użyta podczas testu przesyłania multimediów została wykonana na rynku w Krakowie, co można wywnioskować z opisu zdjęcia przedstawiającego widok na kościół od strony \"Adasia\", co odnosi się do pomnika Adama Mickiewicza na Rynku Głównym w Krakowie.'),\n",
       " ('03',\n",
       "  'Bomba chciał znaleźć hotel w Grudziądzu, aby cofnąć się w czasie i czekać tam dwa lata.'),\n",
       " ('04', 'Rafał pozostawił resztki pizzy z ananasem.'),\n",
       " ('05',\n",
       "  'Litery BNW w nazwie nowego modelu językowego BNW-01 pochodzą od „Brave New World” – Nowy Wspaniały Świat.')]"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = {\n",
    "    question_id: answer for question_id, answer in answers\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aidevs3.poligon import send\n",
    "\n",
    "url = os.environ.get(\"AG3NTS_CENTRALA_URL\") + \"/report\"\n",
    "task = \"arxiv\"\n",
    "api_key = os.environ.get(\"AG3NTS_API_KEY\")\n",
    "res = send(url, task, api_key, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'code': 0, 'message': '{{FLG:BADANIA}}'}"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
