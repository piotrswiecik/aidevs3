{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = Path(os.getcwd())\n",
    "data_path = cwd.parent / \"data\" / \"pliki_z_fabryki\" / \"do-not-share\"\n",
    "assert data_path.exists()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding with LlamaIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.core import Settings\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "Settings.embed_model = OpenAIEmbedding()\n",
    "\n",
    "documents = SimpleDirectoryReader(data_path).load_data()\n",
    "index = VectorStoreIndex.from_documents(documents=documents, embed_model=Settings.embed_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = query_engine.query(\"co to jest EIZ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for src in response.source_nodes:\n",
    "    print(src)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process documents one by one\n",
    "# some metadata can be seeded programmatically without calling llm\n",
    "# some will be generated by llm as preprocessing\n",
    "\n",
    "rich_documents = defaultdict(dict)\n",
    "\n",
    "for file in data_path.iterdir():\n",
    "    with open(file, \"r\") as f:\n",
    "        text = f.read()\n",
    "        rich_documents[file.name][\"metadata\"] = {\n",
    "                \"file_name\": file.name,\n",
    "                \"date\": datetime.strptime(file.name.split(\".\")[0], \"%Y_%m_%d\").date().strftime(\"%Y-%m-%d\"),\n",
    "                \"length\": len(text),\n",
    "            }\n",
    "        rich_documents[file.name][\"content\"] = text\n",
    "\n",
    "def extract_main_topic_with_llm(text):\n",
    "    sys_prompt = f\"\"\"\n",
    "    <instrukcje>\n",
    "    W tekście przesłanym przez użytkownika jest zawarta nazwa urządzania militarnego.\n",
    "    Wskaż jaka to nazwa i zwróć ją bez żadnych dodatkowych informacji i komentarzy.\n",
    "    Jest to zawsze jedna nazwa.\n",
    "    Nazwa w tekście może być w innym przypadku niż mianownik - w takim przypadku zwróć przekształconą nazwę w mianowniku.\n",
    "    Nazwa zawsze znajduje się blisko początku dokumentu.\n",
    "    </instrukcje>\n",
    "    <przykłady>\n",
    "    Tekst: Przeprowadzono testy bulbulatora jonowego. Wyniki są obiecujące.\n",
    "    Odpowiedź: bulbulator jonowy\n",
    "    Tekst: W wyniku testów stwierdzono, że kryptonizer jest gotowy do produkcji seryjnej.\n",
    "    Odpowiedź: kryptonizer\n",
    "    Tekst: Wyrzutnia ABC-100\n",
    "    Odpowiedź: wyrzutnia ABC-100\n",
    "    </przykłady>\n",
    "    \"\"\"\n",
    "    return ai.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": sys_prompt},\n",
    "            {\"role\": \"user\", \"content\": text}\n",
    "        ]\n",
    "    ).choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add autogen uuids\n",
    "\n",
    "import uuid\n",
    "\n",
    "for key, document in rich_documents.items():\n",
    "    document[\"metadata\"][\"uuid\"] = str(uuid.uuid4())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use llm to enrich documents with main topic\n",
    "\n",
    "for key, document in rich_documents.items():\n",
    "    document[\"metadata\"][\"main_topic\"] = extract_main_topic_with_llm(document[\"content\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4bcbd1ea-b076-46a4-a7ec-e8e22fa13e5e',\n",
       " 'ffcf1a43-5c4d-45a3-beae-94e24c62ad74',\n",
       " 'cfdbe167-bd91-46d4-b5de-5aa8c6408cdf',\n",
       " 'faeb6d36-bdd9-4bf8-ab5f-acbf11631483',\n",
       " '7977a860-e152-4098-a42d-414c16664e76',\n",
       " '8130b659-ffd3-4be6-a723-d02cc8b14f5e',\n",
       " 'b9b8ed25-c0f6-443e-9e25-88cf5a7ddeac',\n",
       " 'c57462a1-d8dd-4ad8-9dbf-254747e16bf9',\n",
       " '5d877bda-2007-47ea-8a20-9908f76cfa1d',\n",
       " '154edca7-7c86-4c34-b400-ec021b9fe02e',\n",
       " 'db3eaec0-4ac1-4c60-a951-8f8baeb79644',\n",
       " '17ff9abc-48c6-4bfc-8967-7198ec59ed0f',\n",
       " 'b09712bd-0cc4-430c-aefd-dec044b273b0',\n",
       " '4a2cdafa-0ae9-45ba-a48b-f4cf5175e4c9',\n",
       " '419c117b-ef02-4859-a249-8c76faf1daab',\n",
       " '567f9004-0aaf-4e51-be24-a6ad3a82b563',\n",
       " '9243a8e3-38ce-4db3-ab6d-e6d4ac900179',\n",
       " '00521028-9440-44aa-a446-bae85cbb49b4',\n",
       " '250e6aff-d263-4fc7-9545-2cc3fcc2b9e1',\n",
       " '75ea418b-6bcf-41f8-aef3-37e535ffef40',\n",
       " 'f108706c-4e66-491d-9117-14c841905079',\n",
       " 'aaa463a5-509d-4c92-9f5c-9b2aec07e545',\n",
       " '3bcaa167-b220-4126-abf1-7db947d4fccf']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# embed the docs into qdrant\n",
    "\n",
    "from qdrant_client import QdrantClient\n",
    "\n",
    "qdrant = QdrantClient(\":memory:\")\n",
    "\n",
    "docs = [\n",
    "    document[\"content\"]\n",
    "    for _, document in rich_documents.items()\n",
    "]\n",
    "\n",
    "meta = [\n",
    "    {\n",
    "        \"date\": document[\"metadata\"][\"date\"],\n",
    "        \"length\": document[\"metadata\"][\"length\"],\n",
    "        \"main_topic\": document[\"metadata\"][\"main_topic\"]\n",
    "    }\n",
    "    for _, document in rich_documents.items()\n",
    "]\n",
    "\n",
    "ids = [\n",
    "    document[\"metadata\"][\"uuid\"]\n",
    "    for _, document in rich_documents.items()\n",
    "]\n",
    "\n",
    "qdrant.add(\n",
    "    collection_name=\"s03e02\",\n",
    "    documents=docs,\n",
    "    metadata=meta,\n",
    "    ids=ids\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_result = qdrant.query(\n",
    "    collection_name=\"s03e02\",\n",
    "    query_text=\"w raporcie z którego dnia znajduje się wzmianka o kradzieży prototypu broni\",\n",
    "    limit=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date: 2024-03-31, score: 0.8989213246894683\n",
      "Date: 2024-01-29, score: 0.8889468643176821\n",
      "Date: 2024-02-21, score: 0.8807557942665944\n",
      "Date: 2024-02-01, score: 0.8790207616365366\n",
      "Date: 2024-01-27, score: 0.8774150221774103\n",
      "Date: 2024-03-19, score: 0.8759423238160611\n",
      "Date: 2024-04-27, score: 0.8701192074513983\n",
      "Date: 2024-02-15, score: 0.8700239253311656\n",
      "Date: 2024-05-08, score: 0.8681198140472859\n",
      "Date: 2024-01-17, score: 0.864943854040213\n",
      "Date: 2024-03-12, score: 0.8643186968911939\n",
      "Date: 2024-06-02, score: 0.863538909239175\n",
      "Date: 2024-03-02, score: 0.8629254288840875\n",
      "Date: 2024-03-18, score: 0.8611756013408354\n",
      "Date: 2024-01-08, score: 0.860655542984372\n",
      "Date: 2024-05-31, score: 0.860359549409335\n",
      "Date: 2024-02-11, score: 0.8601826504168983\n",
      "Date: 2024-04-18, score: 0.859383416777385\n",
      "Date: 2024-07-05, score: 0.8579143196532768\n",
      "Date: 2024-05-14, score: 0.8564758056480242\n"
     ]
    }
   ],
   "source": [
    "for res in search_result:\n",
    "    print(f\"Date: {res.metadata['date']}, score: {res.score}\")\n",
    "\n",
    "# the result we need is not top ranked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wzbogacanie metadanych\n",
    "\n",
    "W pierwotnej wersji nie ma wystarczająco dobrych metadanych aby search zadziałał. Szukany rezultat jest na 3-5 miejscu.\n",
    "\n",
    "Możliwe rozwiązania:\n",
    "- Dodać słowa kluczowe w ramach techniki contextual retrieval. Tworząc embeddingi tym razem kompresujemy całość tj. tekst + słowa kluczowe.\n",
    "- Wprowadzić re-rank.\n",
    "- Wykorzystać inny embedding -> https://huggingface.co/spaces/mteb/leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keywords_with_llm(text):\n",
    "    sys_prompt = f\"\"\"\n",
    "    <instrukcje>\n",
    "    W tekście przesłanym przez użytkownika jest zawarta nazwa urządzania militarnego.\n",
    "    Wyselekcjonuj z tekstu słowa kluczowe.\n",
    "    Zwracaj uwagę przede wszystkim na nazwy własne, nazwy urządzeń, nazwy miejsc, nazwy jednostek organizacyjnych, zdarzenia, czynności.\n",
    "    Zamień każde słowo kluczowe na formę podstawową.\n",
    "    Zwróć słowa kluczowe w postaci listy oddzielonej przecinkami. Nie stosuj żadnego innego formatowania.\n",
    "    </instrukcje>\n",
    "    \"\"\"\n",
    "\n",
    "    return ai.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": sys_prompt},\n",
    "            {\"role\": \"user\", \"content\": text}\n",
    "        ]\n",
    "    ).choices[0].message.content\n",
    "\n",
    "# use llm to enrich documents with keywords\n",
    "\n",
    "for key, document in rich_documents.items():\n",
    "    document[\"metadata\"][\"keywords\"] = extract_keywords_with_llm(document[\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed the docs into qdrant\n",
    "\n",
    "import json\n",
    "from qdrant_client import QdrantClient\n",
    "\n",
    "qdrant_rich = QdrantClient(\":memory:\")\n",
    "\n",
    "def enrich_content(content: str, meta: dict):\n",
    "    \"\"\"Adds metadata to the content.\"\"\"\n",
    "    return f\"\"\"\n",
    "    <metadata>\n",
    "    {json.dumps(meta)}\n",
    "    </metadata>\n",
    "    <content>\n",
    "    {content}\n",
    "    </content>\n",
    "    \"\"\"\n",
    "\n",
    "docs = [\n",
    "    enrich_content(document[\"content\"], document[\"metadata\"])\n",
    "    for _, document in rich_documents.items()\n",
    "]\n",
    "\n",
    "meta = [\n",
    "    {\n",
    "        \"date\": document[\"metadata\"][\"date\"],\n",
    "        \"length\": document[\"metadata\"][\"length\"],\n",
    "        \"main_topic\": document[\"metadata\"][\"main_topic\"],\n",
    "        \"keywords\": document[\"metadata\"][\"keywords\"]\n",
    "    }\n",
    "    for _, document in rich_documents.items()\n",
    "]\n",
    "\n",
    "ids = [\n",
    "    document[\"metadata\"][\"uuid\"]\n",
    "    for _, document in rich_documents.items()\n",
    "]\n",
    "\n",
    "ids = qdrant_rich.add(\n",
    "    collection_name=\"s03e02_enriched\",\n",
    "    documents=docs,\n",
    "    metadata=meta,\n",
    "    ids=ids\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_result = qdrant_rich.query(\n",
    "    collection_name=\"s03e02_enriched\",\n",
    "    query_text=\"w raporcie z którego dnia znajduje się wzmianka o kradzieży prototypu broni\",\n",
    "    limit=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date: 2024-01-17, score: 0.8731580272940108, keywords: testy, broń, Irradiator XR-25, promieniowanie, materiały, ekosystemy, wnioski, modyfikacja, system, chłodzenie, eksploatacja, prototyp, wersja, rozpylacz, jony, efekty, otoczenie\n",
      "Date: 2024-04-27, score: 0.8719703375670659, keywords: Wysokotemperaturowy Pojemnik Kinetyczny, raport, testy, konstrukcja, generowanie, ekstremalne temperatury, wydobywanie, energia kinetyczna, temperatury, stopnie Celsjusza, stopienie, materiały, twardość, stal, wyniki, niszczenie, wrogie pojazdy, przekształcanie, teren, nieprzyjazny, przeciwnik, wnioski, potrzeba, rozwijanie, trwałość, efektywność, warunki atmosferyczne, roboty badawcze, modyfikacje, portfel zastosowań, wojskowe operacje, postapokaliptyczne\n",
      "Date: 2024-01-29, score: 0.8712197477551457, keywords: broń, kryptonim, plazmowy, korpus, zniszczenia, testy, wyniki, zasięg, działanie, moc, wystrzał, temperatura, materiał, wnioski, użycie, przestrzeń, nadzór, katastrofa, ekologiczny, powód, badania, bezpieczeństwo, operacyjny, technologia, redukcja, emisja, termalny, plany, przyszłość, model, system, zabezpieczenie, warunki, bojowy\n",
      "Date: 2024-02-11, score: 0.8684151891063161, keywords: Plazmowy miotacz impulsowy, broń, wyniki, testy, efektywność, obiekty mechaniczne, skuteczność, cel biologiczny, pomiary, czas, ładowanie, urządzenie, sytuacje bojowe, kontratak, roboty badawcze, praca, mobilność, wersja, moduły, zasięg, precyzja, plany, przyszłość, badania, możliwość, zdalne sterowanie, użyteczność, pole bitwy\n",
      "Date: 2024-03-31, score: 0.8657761700745843, keywords: broń, Dynamo-3, prototyp, wyrzutnik, pocisk, plazma, test, cel, zasięg, metr, precyzja, problem, wydajność, zasilanie, awaria, użytkowanie, wnioski, przeprojektowanie, źródło, energia, stabilność, działanie, plany, przyszłość, materiał, konstrukcja, bateria, optymalizacja, algorytm, zarządzanie, ciepło, czas, operacyjny\n"
     ]
    }
   ],
   "source": [
    "for res in search_result:\n",
    "    print(f\"Date: {res.metadata['date']}, score: {res.score}, keywords: {res.metadata['keywords']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dalsze usprawnienia\n",
    "\n",
    "Wzbogacenie metadanych nie zadziałało. Nie pomoże nawet filtrowanie po słowach kluczowych - bo w top 5 rezultatów nie ma dobrego kandydata.\n",
    "\n",
    "Sprawdzamy inny embedding - jina-embeddings-v3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/jinaai/xlm-roberta-flash-implementation:\n",
      "- configuration_xlm_roberta.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/jinaai/xlm-roberta-flash-implementation:\n",
      "- rotary.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/jinaai/xlm-roberta-flash-implementation:\n",
      "- xlm_padding.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/jinaai/xlm-roberta-flash-implementation:\n",
      "- mlp.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/jinaai/xlm-roberta-flash-implementation:\n",
      "- embedding.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/jinaai/xlm-roberta-flash-implementation:\n",
      "- mha.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/jinaai/xlm-roberta-flash-implementation:\n",
      "- stochastic_depth.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/jinaai/xlm-roberta-flash-implementation:\n",
      "- block.py\n",
      "- stochastic_depth.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/jinaai/xlm-roberta-flash-implementation:\n",
      "- modeling_xlm_roberta.py\n",
      "- mha.py\n",
      "- block.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/jinaai/xlm-roberta-flash-implementation:\n",
      "- modeling_lora.py\n",
      "- rotary.py\n",
      "- xlm_padding.py\n",
      "- mlp.py\n",
      "- embedding.py\n",
      "- modeling_xlm_roberta.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "class JinaEmbeddings:\n",
    "    def __init__(self):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"jinaai/jina-embeddings-v3\")\n",
    "        self.model = AutoModel.from_pretrained(\"jinaai/jina-embeddings-v3\")\n",
    "\n",
    "    def encode(self, texts):\n",
    "        if isinstance(texts, str):\n",
    "            texts = [texts]\n",
    "\n",
    "        encoded = self.tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "        with torch.no_grad():\n",
    "            model_output = self.model(**encoded)\n",
    "        \n",
    "        embeddings = model_output.last_hidden_state[:, 0, :]\n",
    "\n",
    "        embeddings = embeddings.numpy()\n",
    "        embeddings = embeddings / np.linalg.norm(embeddings, axis=1, keepdims=True)\n",
    "\n",
    "        return embeddings\n",
    "    \n",
    "embeddings = JinaEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "qdrant_jina = QdrantClient(\":memory:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from qdrant_client.http import models\n",
    "\n",
    "qdrant_jina.create_collection(\n",
    "    collection_name=\"s03e02_enriched_jina\",\n",
    "    vectors_config=models.VectorParams(size=1024, distance=models.Distance.COSINE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_content():\n",
    "    def enrich_content(content: str, meta: dict):\n",
    "        \"\"\"Adds metadata to the content.\"\"\"\n",
    "        return f\"\"\"\n",
    "        <metadata>\n",
    "        {json.dumps(meta)}\n",
    "        </metadata>\n",
    "        <content>\n",
    "        {content}\n",
    "        </content>\n",
    "        \"\"\"\n",
    "\n",
    "    docs = [\n",
    "        enrich_content(document[\"content\"], document[\"metadata\"])\n",
    "        for _, document in rich_documents.items()\n",
    "    ]\n",
    "\n",
    "    meta = [\n",
    "        {\n",
    "            \"date\": document[\"metadata\"][\"date\"],\n",
    "            \"length\": document[\"metadata\"][\"length\"],\n",
    "            \"main_topic\": document[\"metadata\"][\"main_topic\"],\n",
    "            \"keywords\": document[\"metadata\"][\"keywords\"]\n",
    "        }\n",
    "        for _, document in rich_documents.items()\n",
    "    ]\n",
    "\n",
    "    ids = [\n",
    "        document[\"metadata\"][\"uuid\"]\n",
    "        for _, document in rich_documents.items()\n",
    "    ]\n",
    "\n",
    "    return docs, meta, ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs, meta, ids = prepare_content()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UpdateResult(operation_id=0, status=<UpdateStatus.COMPLETED: 'completed'>)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qdrant_jina.upsert(\n",
    "    collection_name=\"s03e02_enriched_jina\",\n",
    "    points=[\n",
    "        models.PointStruct(\n",
    "            id=id,\n",
    "            vector=embeddings.encode(doc).tolist(),\n",
    "            payload={\"doc\": doc, \"date\": meta[\"date\"], \"main_topic\": meta[\"main_topic\"]}\n",
    "        )\n",
    "        for doc, id, meta in (zip(docs, ids, meta))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"W raporcie, z którego dnia znajduje się wzmianka o kradzieży prototypu broni?\"\n",
    "\n",
    "results = qdrant_jina.search(\n",
    "    collection_name=\"s03e02_enriched_jina\",\n",
    "    query_vector=embeddings.encode(query)[0],\n",
    "    limit=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-21\n"
     ]
    }
   ],
   "source": [
    "answer = results[0].payload[\"date\"]\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'code': 0, 'message': '{{FLG:ZLODZIEJ}}'}\n"
     ]
    }
   ],
   "source": [
    "from aidevs3.poligon import send\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "key = os.environ.get(\"AG3NTS_API_KEY\")\n",
    "url = f\"{os.environ.get(\"AG3NTS_CENTRALA_URL\")}/report\"\n",
    "\n",
    "\n",
    "res = send(url, answer=answer, apikey=key, task=\"wektory\")\n",
    "print(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
