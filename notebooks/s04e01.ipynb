{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import httpx\n",
    "import json\n",
    "\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel\n",
    "from typing import Optional, Any\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_url = f\"{os.environ.get(\"AG3NTS_CENTRALA_URL\")}/report\"\n",
    "api_key = os.environ.get(\"AG3NTS_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ApiRequest(BaseModel):\n",
    "    task: str = \"photos\"\n",
    "    apikey: str = api_key\n",
    "    answer: str\n",
    "\n",
    "class ApiResponse(BaseModel):\n",
    "    code: int\n",
    "    message: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_request(query: str):\n",
    "    data = ApiRequest(answer=query)\n",
    "    response = httpx.post(api_url, data=data.model_dump_json())\n",
    "    return ApiResponse(**response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "send_request(\"START\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'plan function'\n",
    "\n",
    "system_prompt = f\"\"\"\n",
    "<ROLA>\n",
    "Jesteś asystentem pracującym z REST API umożliwiającym pobieranie i obróbkę zdjęć.\n",
    "Twoją rolą jest zarządzanie komunikacją z REST API w taki sposób aby zrealizować zadanie - pośród zdjęć dostępnych w API \n",
    "musisz znaleźć osobę o imieniu Barbara i sporządzić jej dokładny rysopis.\n",
    "Realizujesz tę funkcję poprzez budowanie odpowiednich obiektów JSON (bez bloku markdown) zawierających instrukcje dla API i analizując zwrócone odpowiedzi.\n",
    "Do dyspozycji masz historię wszystkich dotychczasowych interakcji z API.\n",
    "Generuj kolejne zapytania do API do momentu aż uznasz że posiadasz rysopis poszukiwanej osoby.\n",
    "Rysopis musi pozwalać na identyfikację danej osoby na podstawie wyglądu, rysów twarzy lub cech charakterystycznych.\n",
    "Nie wystarczy sama sylwetka albo ogólne kontury.\n",
    "</ROLA>\n",
    "<CEL>\n",
    "Wytypowanie zdjęcia przedstawiającego Barbarę i sporządzenie rysopisu tej osoby.\n",
    "</CEL>\n",
    "<FORMAT ODPOWIEDZI>\n",
    "Przestrzegaj poniższego formatu odpowiedzi.\n",
    "W szczególności \"command\" musi zawsze być listą - nawet jeśli to jedna komenda to umieść ją wewnątrz listy.\n",
    "{{\n",
    "    \"thinking\": \"dokładny opis twojego rozumowania i procesu decyzyjnego, planowanych kroków\",\n",
    "    \"command\": [\"lista komend do wywołania sposród dostępnych komend opisanych w sekcji ZASADY\", \"komenda 2\", \"komenda 3\"]\n",
    "}}\n",
    "</FORMAT ODPOWIEDZI>\n",
    "<ZASADY>\n",
    "- Masz do dyspozycji komendy START, REPAIR, DARKEN, BRIGHTEN, DESCRIBE, READY.\n",
    "- Komenda START rozpoczyna proces analizy - pobranie informacji o dostępnych zdjęciach z API.\n",
    "- Komenda DESCRIBE służy do generowania opisów zawartości zdjęć.\n",
    "- WAŻNE - komendy DESCRIBE używaj wyłącznie w odniesieniu do zdjęć których jeszcze nie analizowałeś przy pomocy tej komendy.\n",
    "NIGDY nie analizuj tego samego zdjęcia (o tej samej nazwie pliku) więcej niż jednokrotnie.\n",
    "- WAŻNE - komendy DESCRIBE nie łącz w tym samym kroku z komendami REPAIR, DARKEN, BRIGHTEN.\n",
    "- Komenda REPAIR pozwala naprawić zdjęcie zawierające szumy i glitche.\n",
    "- Komenda DARKEN rozjaśnia fotografię.\n",
    "- Komenda BRIGHTEN przyciemnia fotografię.\n",
    "- Komendy mają zawsze format NAZWA_OPERACJI NAZWA_PLIKU - na przykład REPAIR IMG_123.PNG. \n",
    "- Wyjątkiem jest komenda START która występuje samodzielnie i tylko jako pierwsza w zadaniu.\n",
    "- Wyjątkiem jest komenda READY która oznacza zakończenie zadania.\n",
    "- Gdy uznasz że rysopis jest gotowy, użyj komendy READY a w polu \"thinking\" przekaż odpowiedź.\n",
    "- W jednym kroku możesz wydać kilka komend jeśli jest to niezbędne na przykład do równoczesnej analizy wielu zdjęć.\n",
    "</ZASADY>\n",
    "<PRZYKŁADY>\n",
    "1. \n",
    "IN: null,\n",
    "OUT:\n",
    "{{\n",
    "    \"thinking\": \"zaczynamy od pobrania listy zdjęć poleceniem START\",\n",
    "    \"command\" \"START\"\n",
    "}}\n",
    "2.\n",
    "IN: \"oto dostępne zdjęcia: http://xx.com/FOTO1.PNG, http://xx.com/FOTOX.PNG\"\n",
    "OUT:\n",
    "{{\n",
    "    \"thinking\": \"należy przesłać dostępne zdjęcia do narzędzia tworzącego opisy aby dowiedzieć się co na nich jest\",\n",
    "    \"command\": [\"DESCRIBE http://xx.com/FOTO1.PNG\", \"DESCRIBE http://xx.com/FOTOX.PNG\"]\n",
    "}}\n",
    "3.\n",
    "IN: \"zdjęcie FOTO1.PNG przedstawia jakiś ciemny kształt\"\n",
    "OUT:\n",
    "{{\n",
    "    \"thinking\": \"zdjęcie FOTO1.PNG jest za ciemne, należy je rozjaśnić i następnie przesłać do ponownego opisu\"\n",
    "    \"command\": [\"BRIGHTEN FOTO1.PNG\", \"DESCRIBE FOTO1.PNG\"]\n",
    "}}\n",
    "</PRZYKŁADY>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALLOWED_COMMANDS = [\"START\", \"READY\", \"REPAIR\", \"DARKEN\", \"BRIGHTEN\", \"DESCRIBE\"]\n",
    "\n",
    "def agent_step(history):\n",
    "    if history is None:\n",
    "        history = []\n",
    "    ai = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "    response = ai.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": f\"<HISTORIA>{history}</HISTORIA>\"}\n",
    "        ]\n",
    "    )\n",
    "    decision = response.choices[0].message.content\n",
    "\n",
    "    decision_dict = json.loads(decision)\n",
    "    \n",
    "    # call relevant api here\n",
    "    commands = decision_dict[\"command\"]\n",
    "    if not isinstance(commands, list):\n",
    "        raise RuntimeError(\"commands in wrong format\")\n",
    "    \n",
    "    step_result = \"\"\n",
    "\n",
    "    for item in commands:\n",
    "        if item == \"START\":\n",
    "            command = \"START\"\n",
    "            target = None\n",
    "            response = send_request(\"START\")\n",
    "            step_result = response.message\n",
    "        elif item == \"READY\":\n",
    "            print(\"READY\")\n",
    "            print(decision_dict[\"thinking\"])\n",
    "            return decision_dict[\"thinking\"]\n",
    "        else:\n",
    "            command, target = item.split(\" \")\n",
    "            assert command is not None\n",
    "            assert command in ALLOWED_COMMANDS\n",
    "            assert target is not None\n",
    "            if not target.startswith(\"https://\"):\n",
    "                target = f\"{os.environ.get(\"AG3NTS_CENTRALA_URL\")}/dane/barbara/{target}\"\n",
    "            print(f\"executing command: {command} -> {target}\")\n",
    "            if command == \"DESCRIBE\":\n",
    "                # if seen\n",
    "                penalty = False\n",
    "                for history_item in history:\n",
    "                    if history_item[\"target\"] == target:\n",
    "                        step_result = f\"Wykonujesz instrukcje niezgodnie z promptem. Zdjęcie {target} było już opisywane przez DESCRIBE. Nie używaj DESCRIBE do tego samego zdjęcia więcej niż raz.\"\n",
    "                        penalty = True\n",
    "                        break\n",
    "                if not penalty:\n",
    "                    # if not seen\n",
    "                    describe_response = ai.chat.completions.create(\n",
    "                        model=\"gpt-4o-mini\",\n",
    "                        messages=[\n",
    "                            {\"role\": \"user\", \"content\": [\n",
    "                                {\"type\": \"text\", \"text\": \"describe this image, if it contains a person then describe appearance\"},\n",
    "                                {\"type\": \"image_url\", \"image_url\": \n",
    "                                    {\n",
    "                                        \"url\": target\n",
    "                                    }\n",
    "                                } \n",
    "                            ]}\n",
    "                        ]\n",
    "                    )\n",
    "                    step_result = describe_response.choices[0].message.content\n",
    "            elif command == \"REPAIR\":\n",
    "                if target.startswith(\"https://\"):\n",
    "                    target = target.split(\"/\")[-1]\n",
    "                response = send_request(f\"{command} {target}\")\n",
    "                print(response)\n",
    "                step_result = response.message\n",
    "            elif command == \"BRIGHTEN\":\n",
    "                if target.startswith(\"https://\"):\n",
    "                    target = target.split(\"/\")[-1]\n",
    "                response = send_request(f\"{command} {target}\")\n",
    "                print(response)\n",
    "                step_result = response.message\n",
    "            elif command == \"DARKEN\":\n",
    "                if target.startswith(\"https://\"):\n",
    "                    target = target.split(\"/\")[-1]\n",
    "                response = send_request(f\"{command} {target}\")\n",
    "                print(response)\n",
    "                step_result = response.message\n",
    "\n",
    "        history.append({\n",
    "            \"step_number\": len(history),\n",
    "            \"thinking\": json.dumps(decision_dict[\"thinking\"]),\n",
    "            \"command\": command,\n",
    "            \"target\": target,\n",
    "            \"api_response\": step_result\n",
    "        })\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step1 = agent_step(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step2 = agent_step(step1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step3 = agent_step(step2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step4 = agent_step(step3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step5 = agent_step(step4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aidevs3.poligon import send\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "key = os.environ.get(\"AG3NTS_API_KEY\")\n",
    "url = f\"{os.environ.get(\"AG3NTS_CENTRALA_URL\")}/report\"\n",
    "\n",
    "res = send(url, answer=step5, apikey=key, task=\"photos\")\n",
    "print(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
